{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38d4929b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO TRANSCRIPT\n",
      "\n",
      "\n",
      "Wow. What an audience. Pratham banane. Ok i think my talk. I don't. Thanks my talk. Today the one cigarette scene in get a seat. Most run in taka new. Here. Sirsa ki nahin. Random person. Strowman facebook. Pics with weight. Kisi back in 2009 we are had this weird thing is called. Attention spans. Which organ. Introducing the last time i watched in 18 minutes i thought. Paneer. Yes. So that's ok. Keep it quick. I am your mine in under a minute. Play 44 seconds right now time for 15 joke. Why are balloons so expensive. Information. \n"
     ]
    }
   ],
   "source": [
    "# importing all libraries \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import speech_recognition as sr \n",
    "import os \n",
    "\n",
    "\n",
    "# creating a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "def get_large_audio_transcription(path):\n",
    "    \n",
    "    #split the audio into chunks \n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "\n",
    "    chunks = split_on_silence(sound,\n",
    "    \n",
    "        min_silence_len = 500,\n",
    "        \n",
    "        silence_thresh = sound.dBFS-14,\n",
    "                              \n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    \n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "\n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                whole_text += text\n",
    "    \n",
    "    return whole_text\n",
    "\n",
    "print(\"AUDIO TRANSCRIPT\")\n",
    "\n",
    "print(get_large_audio_transcription(\"/home/ruchi/Downloads/audio/testaudio.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18702a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "SUMMARIZED AUDIO\n",
      "the one cigarette scene in get a seat. Most run in taka new. Here. Sirsa ki nahin. Random person. Strowman facebook. Pics with weight. Kisi back in 2009 we are had this weird thing is called. Attention spans. Which organ. Introducing the last time i watched in 18 minutes.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json \n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "text = \" \"\n",
    "\n",
    "text = get_large_audio_transcription(\"/home/ruchi/Downloads/audio/testaudio.wav\")\n",
    "\n",
    "\n",
    "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
    "t5_prepared_Text = \"summarize: \"+preprocess_text\n",
    "\n",
    "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "\n",
    "# summmarize \n",
    "summary_ids = model.generate(tokenized_text,\n",
    "                                    num_beams=4,\n",
    "                                    no_repeat_ngram_size=2,\n",
    "                                    min_length=30,\n",
    "                                    max_length=100,\n",
    "                                    early_stopping=True)\n",
    "\n",
    "output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"SUMMARIZED AUDIO\")\n",
    "\n",
    "print (output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e2744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
